# Отчет по лабораторной работе №2

## 1. Задачи лабораторной работы

В данной лабораторной работе были реализованы и проанализированы различные подходы к умножению матриц:

### 1.1. Реализации на CPU:
- **Простое последовательное умножение** — базовый алгоритм с тройным вложенным циклом
- **Умножение через библиотеку Eigen** — использование оптимизированной библиотеки линейной алгебры
- **Многопоточное умножение** — параллелизация вычислений с использованием 8 потоков

### 1.2. Реализации на GPU:
- **Простое CUDA-ядро** — базовая реализация умножения матриц на GPU без использования разделяемой памяти
- **CUDA-ядро с разделяемой памятью (shared memory)** — оптимизированная версия с использованием `__shared__` памяти для уменьшения количества обращений к глобальной памяти

### 1.3. Цели работы:
- Сравнить производительность различных подходов к умножению матриц
- Изучить основы программирования на CUDA
- Понять преимущества использования разделяемой памяти в CUDA
- Оценить эффективность параллельных вычислений на CPU и GPU


## 2. Инструкция по запуску

**Требования:**  `g++`, `nvcc`. Для запуска CPU-версии необходима библиотека `Eigen`. Путь к её include-файлам нужно указать в Makefile.

**Сборка проекта:**

- Сборка CPU-версии: `make build_cpu`
- Сборка GPU-версии: `make build_cuda`
- Очистка сборочных файлов: `make clean`

**Запуск программ:**

Аргументы исполняемого файла - целые числа `M`, `N`, `P`, отвечающие за размеры матриц. Матрица `A` - размера  `MxN`, `B` - `NxP`, результирующая матрица `C` - `MxP`.

- Запуск CPU-версии: `./build/cpu_multiplication <M> <N> <P>`
- Запуск GPU-версии: `./build/gpu_multiplication <M> <N> <P>`

## 3. Примеры работы
### 3.1 Матрицы размера `100x300` и `300x120`
```bash
$ ./build/cpu_multiplication 100 300 120
CPU
Простое умножение заняло: 0.00992893 секунд.
Умножение через Eigen заняло: 0.0013426 секунд.
Многопоточное умножение заняло: 0.0029339 секунд.
Матрицы равны: 1
```

```bash
$ ./build/gpu_multiplication 100 300 120
GPU
Простое умножение заняло: 0.000210784 секунд.
Умножение через shared_memory заняло: 2.2482e-05 секунд.
Матрицы равны: 1
```

### 3.2 Матрицы размера `1000x2000` и `2000x1500`
```bash
$ ./build/cpu_multiplication 1000 2000 1500
CPU
Простое умножение заняло: 12.0407 секунд.
Умножение через Eigen заняло: 0.434437 секунд.
Многопоточное умножение заняло: 1.95935 секунд.
Матрицы равны: 1
```

```bash
$ ./build/gpu_multiplication 1000 2000 1500
GPU
Простое умножение заняло: 0.044959 секунд.
Умножение через shared_memory заняло: 4.8974e-05 секунд.
Матрицы равны: 1
```

## 4. Выводы

**Реализации на CPU**
1. **Простое последовательное умножение** является самым медленным методом, так как не использует никаких оптимизаций.
2. **Умножение через Eigen** показывает наилучшую производительность среди CPU-реализаций благодаря внутренним оптимизациям библиотеки. Также  `Eigen` может автоматически подключаться к GPU при обнаружении заголовочных файлов.
3. **Многопоточное умножение** занимает промежуточное положение - быстрее простого последовательного алгоритма за счет параллелизма, но медленнее Eigen из-за накладных расходов на создание потоков и синхронизацию. Эффективность зависит от размера матриц и количества доступных ядер процессора.

**Реализации на GPU**
1. **Простое CUDA-ядро** обеспечивает значительное ускорение по сравнению с CPU-реализациями для больших матриц благодаря массивому параллелизму и высокой пропускной способности памяти GPU.
2. **CUDA-ядро с разделяемой памятью** показывает еще лучшую производительность. Использование `__shared__` памяти значительно уменьшает количество обращений к глобальной памяти - к каждой ячейке глобальной памяти происходит обращение только при копировании, а многократные обращения при вычислении происходят к `__shared__` памяти, обладающей меньшей латентностью. Оптимизация особенно заметна для больших матриц.


Для малых матриц (до 100x100) накладные расходы на передачу данных между CPU и GPU могут превышать выигрыш от параллелизма. Реализации через Eigen могут быть быстрее и наивной, и параллельной реализации. Для средних и больших матриц  GPU-реализации показывают значительное превосходство, ускорение может достигать сотен раз по сравнению с простым CPU-алгоритмом даже с учетом расходов на перенос матриц с CPU на GPU и обратно.


**Технические особенности реализации**
- **Размер блока в CUDA**: используется блок размером 16x16 потоков (`BLOCK_DIM = 16`), что является оптимальным для большинства современных GPU
- **Многопоточность на CPU**: используется 8 потоков, что соответствует типичному количеству ядер в современных процессорах
- **Тип данных**: все реализации используют тип `float`, что обеспечивает баланс между точностью и производительностью
